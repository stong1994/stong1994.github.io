<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>cristo</title>
    <link>https://stong1994.github.io/internet/</link>
    <description>Recent content on cristo</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language>
    <lastBuildDate>Sat, 20 Nov 2021 13:20:00 +0800</lastBuildDate><atom:link href="https://stong1994.github.io/internet/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>浅谈分层</title>
      <link>https://stong1994.github.io/internet/depth/layer/</link>
      <pubDate>Sat, 20 Nov 2021 13:20:00 +0800</pubDate>
      
      <guid>https://stong1994.github.io/internet/depth/layer/</guid>
      <description>笔者在工作过程中遇到了一些分层相关的问题，于是将问题和想法记录下来，以供未来回顾。
提出问题  什么是分层 为什么要分层 怎样做分层  什么是分层 这是一个很简单的问题。
这也是一个很复杂的问题。
简单之处在于每个人都能做出回答，复杂之处在于这其实是个通用问题。
通用问题是啥？百度百科上是没有这个词条的，因为我不知道这类问题如何划分，所以随便造了个词，或者称为底层逻辑问题更好理解些？
程序员当然知道有哪些分层：控制层-逻辑层-数据对象层、前台层-中台层等等。
但生活中的分层要更多。
 每天早上吃的鸡蛋有分层：蛋壳、蛋白、蛋黄 上班路上两边的树木有分层：树根、树干、树冠、树叶，或者将其拦腰斩断，能看到层次分明的年轮 坐电梯时可能更能体会到分层——每层楼都是一层。 进入公司，销售部、行政部、研发部等等也在分层 连我们人体本身也满是分层：上半身、下半身、头、胳膊、脚，或者皮肤、脂肪、血液、骨骼、神经等等  分层是这个世界的基本规则之一。
思维的发散就到此为止吧，因为我已经发现没有办法直面我们最初的三个问题了。
所以让我们来简化下问题——将问题的讨论范围限制在代码内。
对于什么是分层——我先给出我的答案——分层就是对代码按照某种规则进行切分。
至于为什么是这个答案，下面会讲。
为什么要分层 我们先来回顾下分层的演进。
最早的分层是什么呢，那一定是没有分层。当我们打印出“hello world&amp;quot;时，我们是没有分层的。
让我们继续写代码。我可能要在前端展示一些文字，这些文字可能存储在数据库中。如果仅仅是这样的话，我们很可能还是没有分层——功能实在是太简单了。
直到有一天，我们写了上千行的代码，突然发现代码已经很难维护了，因为数据模型、业务逻辑、前端代码等都混在一起，于是我们本能的开始分层，于是一个伟大的概念产生了——MVC。
MVC最早据说是起源于桌面端开发，M代表数据层，V代表UI层，C代码控制层，通过分离这三层，我们的代码已经是很清晰了。
但是该死的产品经理还在没完没了的增加那些不知道有什么用的功能。
于是代码开发者发现三层不够用，于是把前端和后端代码进行了隔离，也就是前后端分离。后端仍旧是分层，不过是改为了控制层-逻辑层-数据层（controller-service-model）。那么前端呢？前端都分出去了，我们就不管了。
 这里有个逻辑要叙述下。有些人认为是ajax这类技术的产生才导致了前后端分离。这种想法属实是本末倒置了，任何技术的产生都来源于需求！
 我对于controller-service-model这种分层可谓是异常熟悉，因为就在我大学实习的时候，就用的这种分层。当时用得是java的SSM框架，三个框架正好对应这三层（java好像搞啥都是一整套？）。这几个框架让我深受贫血模型的影响，即使我后来不写Java了（以后可以聊下如何避免写贫血模型）。
时代在发展，软件的用户越来越多，功能越来越复杂，开发人员越来越多。代码也越来越臃肿。
于是某个大佬发明了微服务的概念，再然后某个大佬发明了中台的概念。
于是我们不仅有前后端的分层，还有后端与后端的分层——前台、中台、支撑的分层。
回到我们的问题——为什么要分层——答案应该已经很明确了，就是为了解决代码的臃肿问题，让代码更清晰！
怎样做分层 服务分层  现状：目前公司内有很多中台仅仅是对数据库的CRUD的封装（看起来就像是封装了一个使用http做传输的ORM框架），业务逻辑仍集中在前台。这种中台没有任何意义，似乎只是为了分层而分层，或者说为了做中台而分层。进一步的原因就是设计者对中台缺乏认知。
 目前公司内的项目存在两种分层方式：按功能划分与按业务划分。
以报表功能举例：我们在多种场景中都需要报表功能，如人事报表、招聘报表。这些报表都有自己的业务逻辑，不能进行统一处理，但是都需要订阅功能，且存在业务逻辑：当用户删除报表时，需要同时删除用户对该报表的订阅（该功能在下文用功能A标识）。
按功能划分 根据功能的性质划分，此时订阅功能和报表功能为同等级功能。
此时会存在：报表中台、报表前台、订阅中台、订阅前台。
功能A应在报表前台来实现。
按业务划分 按照业务来划分，此时订阅功能应被视为报表的附属功能。
此时会存在：招聘报表中台、招聘报表前台、人事报表中台、人事报表前台。
功能A应在招聘报表中台和人事报表中台分别实现。
划分手段 上边直接说了结论，那么这样划分的依据是什么？
首先必须要分为中台和前台：中台作为业务的聚合，而前台作为对前端的适配。这样能保证业务逻辑的内聚，使中台专注于自己的业务，避免易变的产品需求对业务核心代码的侵蚀。
其次一定要让服务有明确的边界。设计者不能凭感觉来划分服务，一定要有自己的方法论作为指导基础。如果只凭感觉来划分，最终的结果就是服务之间没有边界，导致中台服务冗余了大量不属于自己领域内的代码。
所以不管是按功能划分还是按业务划分又或者有其他划分方法，总之设计者一定要有自己的划分方法论。
代码分层  现状：目前公司内大量项目的代码结构为controller+business+service。business做业务逻辑，service做服务实现。换句话说，就是将以前的service层改名为business，以前的model改名为service。这种改变的逻辑是：微服务时代需要大量调用其他服务，model不具有此含义，因此需要将model改名为service，用service来处理调用其他服务的逻辑。
这种结构在实际开发中面临一个非常严重的问题——business和service的边界模糊——导致service层的代码和business层代码混在一起——导致本就复杂的业务层代码更加复杂且难以理解。
 问题：如何解决business和service的边界模糊问题
边界模糊的原因1：词汇描述能力不足。我们一般使用service来写业务逻辑，现在换用了business，但是仍保留service层来做服务调用，这增加了开发者对service和business语义上的模糊。另外，从读者的角度来看，这种命名会让人十分疑惑。</description>
    </item>
    
    <item>
      <title>查询一条mysql都经历了什么</title>
      <link>https://stong1994.github.io/internet/depth/mysql_query/</link>
      <pubDate>Wed, 06 Oct 2021 17:05:00 +0800</pubDate>
      
      <guid>https://stong1994.github.io/internet/depth/mysql_query/</guid>
      <description>在客户端执行一条mysql查询命令，到客户端接收到查询结果，这中间mysql服务器都做了哪些事情呢？
先来了解下mysql体系架构。
mysql体系架构 图片来自: https://segmentfault.com/a/1190000039693313
以上图为对照，mysql的查询会经历大致以下过程：
 客户端与服务端建立连接 查询缓存 将请求的SQL进行解析，并进行语法校验 通过优化器来优化SQL，生成执行计划 选择对应的存储引擎来执行计划，获取数据 向客户端返回查询结果  那么我们就来分别看看这几步都做了哪些事情。
建立连接 </description>
    </item>
    
    <item>
      <title>异地多活</title>
      <link>https://stong1994.github.io/internet/design/dboat/</link>
      <pubDate>Mon, 04 Oct 2021 22:32:00 +0800</pubDate>
      
      <guid>https://stong1994.github.io/internet/design/dboat/</guid>
      <description>背景 随着用户的日益增多，系统的质量问题越来越突出。
想象一下：用户正在使用软件，突然软件崩溃了、不能用了，这时候用户肯定要理(ma)解(niang)的。如果一年只崩溃一两次还好（当然，如飞机、火车运行所需要的软件是绝对不能出问题的），如果每隔几天就来这么一下，那么用户可能就要寻找替代品了。2B的产品更是如此（业内通常使用SLA来描述可靠性，也就是大佬们常说的4个9、5个9）。
提升服务质量的手段有很多，如：
  良好的代码风格、积极的code review、完善的自动化测试——在根上减少问题出现的可能性
  合理的监控、报警、预警——保证第一时间内得到通知甚至提前预知风险
  科学的熔断策略——减小一个低质量的服务造成全体系统崩溃的风险
  完善的链路追踪、日志系统——提高解决问题的速度
  善用灰度网关——减少重构系统带来的风险以及损失
  。。。
  尽管目前的手段众多，但是如果一个地区发生了“黑天鹅”事件，如没有预警的停电、地震、海啸，又碰巧这就是我们的服务器所在地，那么上述手段也是无能为力。
所以我们就需要更强大的容灾方案——异地多活。
目标 实现两地三中心方案。
什么是两地三中心？就是在两个区域部署三套服务——一个区域一套，另外一个区域两套。大部分两地三中心是在同城双活的基础上，增加了异地灾备数据中心。而对我们来说，其实就是实现的多区域同步设计方案，只是在实施上是两地三中心。
为什么不是三地三中心？因为城市之间要通过光缆来传输数据，而这是一笔很大的开销。
功能列表：
 用户“就近访问” 区域之间的数据同步 一个区域的服务器宕机后，流量自动打到其他区域 等  仅看这个功能列表，很多细节都很模糊（不是模糊，是根本就没有），我们先看设计方案，然后再把剩余的细节问题解决。
设计方案 两区域间单向的数据流 上图是区域之间数据的单向流动。
 数据库的同步组件选择了阿里开源的canal，它会模拟从服务器来获取数据库的binlog canal支持tcp、kafka、rocketmq三种同步方式，我们选择kafka 发送端：主动发起同步的区域从kafka中获取到数据，然后发往被同步的区域 接收端：被同步的区域接收数据的服务即为接收端，接收到数据后会放到kafka中。这里kafka的作用是削峰与暂时的持久化。 回放端：从第四步中的kafka中获取数据，解析为sql，并执行，完成数据的回放  以上步骤解决了两个区域之间的单向同步
两区域间双向的数据流 跟前一张图相比，只是进行了“镜像复制”，逻辑没有增加。
但是我们发现了数据回环——即从A区域的数据同步到B区域之后，又回到了A区域。如何打断数据回环？
一般来说，我们以“就近原则”为准，能在B区域打断就不要在A区域打断，这样至少能减少数据传输。
我们能控制得只有接收端、回放端和发送端，并且需要在入库之前打上标记，入库拿到数据之后进行过滤。根据“就近原则”，我们在回放端标记数据，在发送端进行数据过滤。具体方案如下：
将数据信息记录到redis的hash中，key为`replay:{数据库名}:{表名}`， field和value规则如下： 1. 对于DDL, field为crc32(sql)+区域标识, value为serverID 2. 对于插入, field为操作类型标识+主键ID+区域标识， value为来源serverID 3. 对于删除, field为操作类型标识+主键ID+区域标识， value为来源serverID 4. 对于更新, field为操作类型标识+主键ID+crc32(after)+区域标识, value为来源serverID  其中serverID为数据库实例的唯一标识，这里只来源实例。 after为更新后的列数据，在实现中是一个结构体。插入和删除都是幂等的，因此不需要记录列信息，更新操作需要判断是否为同一条语句只用主键是不行的，所以需要记录列信息。  发送端从kafka获取到数据后，先判断数据是否是回环数据，如果是则过滤，然后删除缓存。</description>
    </item>
    
    <item>
      <title>灰度网关</title>
      <link>https://stong1994.github.io/internet/design/gray_gateway/</link>
      <pubDate>Sun, 03 Oct 2021 23:57:00 +0800</pubDate>
      
      <guid>https://stong1994.github.io/internet/design/gray_gateway/</guid>
      <description>背景 对于一个公司来说，在创业初期需要对产品快速迭代来解决用户痛点、提升自己的竞争力进而占领更多的市场（这就是MVP原则的思想）。随着业务的发展，早期的快速迭代导致了代码冗余、混乱、质量低、难以维护等问题，这时候就需要对其进行重构。
但是重构会带来极大的风险，严重的会导致服务崩溃，甚至是数据混乱。这是我们不能接受的。
尽管重构的风险是无法避免的，但是我们却可以通过管控流量将风险降到最低。这就用到了灰度网关。
此外，灰度网关还支持A/B测试等其他方面的功能。
功能简介  支持将旧服务的流量打到新服务 支持按照一定的比例来分配流量 支持按照header或者ip来分配流量 支持动态配置  正常情况下的流量走向 灰度后的流量走向 技术选型 开发网关，那首选就是openresty了。openresty是一个以nginx作为网络通信，以lua语言进行开发的平台，也可以理解为是一套可以通过lua语言对nginx进行扩展的生态。
由于需要支持动态配置，因此需要一个配置中心，我们选择了consul（整体系统的配置中心都是用的consul）。
开发思路 nginx执行阶段选择 先来回顾下nginx的11个执行阶段。
openResty的11个*_by_lua指令，对应了nginx的11个执行阶段。以下是其应用场景：
 init: 只会在 Master 进程被创建时执行 init_worker: 只会在每个 Worker 进程被创建时执行 ssl_certificate: 证书认证 set: 设置变量 rewrite: 转发、重定向 access：权限控制 content：生成内容返回 balancer：负载均衡 header_filter: 响应头过滤 body_filter: 响应体过滤 log: 日志记录  通过上图，我们可以得出结论：我们只能在set、rewrite、access这三个阶段进行灰度处理
判断流量走向 首先，如果url没在配置中，那么流量一定是打入到原环境。
如果url在配置中，那么流量需要按照比例判断是否打入到灰度环境还是原环境。
判断url是否在配置：
 通过ngx.var.uri即可拿到访问url，然后再去配置中心进行匹配即可。  判断该请求打入到哪个环境：
  在头部拿到token：ngx.req.get_headers()
  如果token为空获取ip：
local headers = ngx.req.get_headers() local ip = headers[&amp;#34;X-REAL-IP&amp;#34;] if ip == nil then ip = ngx.</description>
    </item>
    
    <item>
      <title>事件分发平台</title>
      <link>https://stong1994.github.io/internet/design/evps/</link>
      <pubDate>Fri, 01 Oct 2021 19:26:00 +0800</pubDate>
      
      <guid>https://stong1994.github.io/internet/design/evps/</guid>
      <description>背景 随着业务的增长，一个事件开始被多个子系统订阅，如用户注册事件就可能被处理用户逻辑的子系统和日志系统订阅。以往我们在处理这些逻辑的时候，要么在处理完注册逻辑后，调用多个子服务接口，要么用消息队列中间件来处理。这些都导致了较高的维护成本。
另外，整体系统使用了严格的分层，下层服务不能调用上层服务，同层之间也不能调用。如果有回调等需求，也要通过事件的方式来传递数据。
因此，我们基于消息队列的思想，创建了事件分发平台。
架构设计 整个事件分发系统大致由以下构成：
 事件发送方：即事件的生产者 事件订阅方：即事件的消费者 事件分发服务：接收事件，处理事件的发送逻辑 事件管理平台：通过web页面管理事件的配置，显示错误日志等信息  我们主要关注事件分发服务：
 订阅者队列组：每个订阅方（事件接收方）都有自己单独的队列，因此生产者和订阅者队列是一对多的关系。订阅者队列组来管理一个事件的多个订阅队列（实际上订阅队列组在上层还有一个订阅者队列管理器，来统一管理这些订阅队列组，与业务逻辑无关，因此图中未显示）。 订阅者集群组：每个订阅者队列都对应着一个订阅者集群，该集群由多个channel组成，用来加快事件的消费速度。集群具备自动扩容、缩容的功能。 配置中心：配置中心是通过内存来存储着事件的订阅关系。配置中心通过读取或者监听redis的变动，来管理订阅关系。订阅者队列组和订阅者集群组都会读取配置中心并监听配置中心变动，来管理自己的队列或集群。  消息队列中间件的选择 事件分发平台是基于消息队列的思想来构建的，因此需要使用消息队列中间件来管理消息队列。
市面上有许多消息队列中间件，如kafka、rabbitmq等。我们考虑到所需吞吐量并不大，所以初步选择使用redis的列表来实现。使用redis的列表来实现，优势在于能够更快速的完成开发，且整体系统更轻量。
一旦发展到redis的列表不能满足需求时，通过接口或者叫适配器，也能轻松的完成消息队列中间件的切换。
如何监听redis中的事件变动 在事件管理平台将事件订阅关系变动后，会将数据存储到redis中。配置中心如何监听这些数据的变动呢？
每隔一段时间就读取全量数据是最简单的做法，也是最粗暴的做法。因为事件数据有很多，每次读取、对比都需要不少的时间，这就导致事件分发服务对于事件配置的变动很“迟钝”。
我们通过版本号的方法来解决。通过一个hash来存储发送者信息、事件信息、订阅者信息、订阅关系信息的版本号，每次修改这些信息时，都要对其对应的版本号自增。同时，事件分发服务在内存中也会维护这样一个版本号，每隔一段时间（如200ms）读取一次，进行更新，当事件分发服务发现版本号不对的时候，就会去拉取对应的数据，来更新内存中的数据。
这样每次只读取一个很小的hash key即可知道哪些数据需要更新。
消费逻辑 有以下几点需要注意：
 有些订阅者服务需要按照时序来接收事件 系统处于维护状态时，不能接收事件，需要将事件暂存  整体流程图如下：
其中时序功能采用最简单“先到先得”，即按照事件分发服务接收到请求的时间来排序。
可进一步优化的地方 在发送事件时，如果发送失败会进行重试，但是如果超过了重试次数，那么该事件就会丢失。
可考虑在发送失败后报警并每隔一段时间进行发送，直到服务恢复正常，能够正常返回数据时，再继续消费数据。</description>
    </item>
    
    <item>
      <title>统一支付系统</title>
      <link>https://stong1994.github.io/internet/design/basepay/</link>
      <pubDate>Thu, 30 Sep 2021 14:31:11 +0800</pubDate>
      
      <guid>https://stong1994.github.io/internet/design/basepay/</guid>
      <description>背景 已有的支付服务经常出现支付失败、支付状态不准确等问题，且由于历史原因使用的.net开发，维护上有一定困难，因此我们决定重新做一个统一支付系统。
需求 统一支付系统需要满足以下几点需求：
 对接微信、支付宝中的多种支付方式 处理微信、支付宝的回调结果，并通过事件分发平台通知业务方。 开发环境和测试环境要支持1分钱开关，打开开关后，任何支付都是1分钱 支持退款 需要对账功能  架构设计   红色流程为订单的预支付流程。
  黄色流程为用户支付流程，为用户与第三方服务商交互。
  绿色流程为第三方服务商回调流程
  预支付流程  用户在客户端点击商品选择支付 业务系统处理订单逻辑，并调用通用支付系统发起下单请求 通用支付系统调用对应的第三方服务商，获取支付二维码地址或者唤起客户端支付地址，并返回给业务系统，业务系统将其返回给前端 前端接收到地址后，将其转换为二维码或者调换到微信/支付宝客户端支付页面  回调流程   第三方服务商在收到用户支付或者拒绝后，会发送支付结果到回调网关
  回调网关对数据进行解密、校验并将解析出来的数据发往事件分发平台
  由于通用支付系统订阅了该事件，因此事件分发平台会将该事件发送给通用支付系统
  通用支付系统处理支付结果，并将最终的支付状态通过事件分发平台发送给业务子系统
  时序图-以微信的Native支付为例 注意事项 支付和退款分离 由于是统一支付系统，需要兼容各服务商的支付和退款，因此，为了高扩展性，将支付和退款作为两种订单处理，每种都有自己的订单状态
统一支付接口参数 支付宝和微信的支付接口支持非常多的参数，这其中大部分是用不到的，因此在做接口设计时，没必要将这些参数放进去，保持接口的简洁。
统一支付/退款状态 支付宝和微信的支付/退款状态并不同。
 微信有：未支付、已关闭、已撤销、支付失败、支付成功、转入退款、等待扣款 支付宝有：订单创建、交易成功、交易超时或者已全额退款、交易结束  作为统一支付系统，我们需要有自己的一套交易状态来兼容第三方服务商的交易状态。
支付状态：
 交易创建：即未收到任何回调时 交易成功：存在真实的资金流动 交易失败：由于服务商内部服务原因导致交易失败，比如由银行返回的支付失败。 交易关闭：没有真实的资金流动，如交易被撤销，用户付款超时导致交易取消  退款状态：
 退款订单创建 退款关闭 退款成功 退款失败  统一单位 微信支付的最小单位为分，而支付宝的单位为元，支持小数。统一支付接口设计上以分为单位，不支持小数。</description>
    </item>
    
    <item>
      <title>DDD实战-笔记篇</title>
      <link>https://stong1994.github.io/internet/ddd/practise/</link>
      <pubDate>Fri, 29 Jan 2021 23:31:51 +0800</pubDate>
      
      <guid>https://stong1994.github.io/internet/ddd/practise/</guid>
      <description>DDD实战 如何构建中台业务模型？ 1. 自顶向下的策略 这种策略是先做顶层设计，从最高领域逐级分解为中台，分别建立领域模型，根据业务属性分为通用中台或核心中台。领域建模过程主要基于业务现状，暂时不考虑系统现状。自顶向下的策略适用于全新的应用系统建设，或旧系统推倒重建的情况。
2. 自底向上的策略 这种策略是基于业务和系统现状完成领域建模。首先分别完成系统所在业务域的领域建模；然后对齐业务域，找出具有同类或相似业务功能的领域模型，对比分析领域模型的差异，重组领域对象，重构领域模型。这个过程会沉淀公共和复用的业务能力，会将分散的业务模型整合。自底向上策略适用于遗留系统业务模型的演进式重构。
第一步：锁定系统所在业务域，构建领域模型。 锁定系统所在的业务域，采用事件风暴，找出领域对象，构建聚合，划分限界上下文，建立领域模型。
可以看到有很多相似的模块
第二步：对齐业务域，构建中台业务模型 传统核心领域模型明显多于左侧的互联网电商。这个结论也给我们指明了一个方向：首先我们可以将传统核心的领域模型作为主领域模型，将互联网电商领域模型作为辅助模型来构建中台业务模型。然后再将互联网电商中重复的能力沉淀到传统核心的领域模型中，只保留自己的个性能力，比如订单。中台业务建模时，既要关注领域模型的完备性，也要关注不同渠道敏捷响应市场的要求。
我们从互联网电商和传统核心的领域模型中，归纳并分离出能覆盖两个域的所有业务子域。通过分析，我们找到了用户、客户、承保、收付和订单五个业务域，它们是可以用于领域模型对比分析的基准域。
构建多业务域的中台业务模型的过程，就是找出同一业务域内所有同类业务的领域模型，对比分析域内领域模型和聚合的差异和共同点，打破原有的模型，完成新的中台业务模型重组或归并的过程。
重构后
构建中台模型的要点 分域建模型，找准基准域，划定上下文，聚合重归类
第三步：中台归类，根据领域模型设计微服务。 完成中台业务建模后，我们就有了下面这张图。从这张图中我们可以看到总共构建了多少个中台，中台下面有哪些领域模型，哪些中台是通用中台，哪些中台是核心中台，中台的基本信息等等，都一目了然。你根据中台下的领域模型就可以设计微服务了。
重构过程中的领域对象 部分领域对象可能会根据新的业务要求，从原来的聚合中分离，重组到其它聚合。新领域模型的领域对象，比如实体、领域服务等，在重组后可能还会根据新的业务场景和需求进行代码重构。
事件风暴需要准备些什么 1. 事件风暴的参与者 除了领域专家，事件风暴的其他参与者可以是 DDD 专家、架构师、产品经理、项目经理、开发人员和测试人员等项目团队成员。
领域建模是统一团队语言的过程，因此项目团队应尽早地参与到领域建模中，这样才能高效建立起团队的通用语言。
2. 事件风暴要准备的材料 事件风暴参与者会将自己的想法和意见写在即时贴上，并将贴纸贴在墙上的合适位置，我们戏称这个过程是“刷墙”。所以即时贴和水笔是必备材料，另外，你还可以准备一些胶带或者磁扣，以便贴纸随时能更换位置。
值得提醒一下的是，在这个过程中，我们要用不同颜色的贴纸区分领域行为。如下图，我们可以用蓝色表示命令，用绿色表示实体，橙色表示领域事件，黄色表示补充信息等。补充信息主要用来说明注意事项，比如外部依赖等。颜色并不固定，这只是我的习惯，团队内统一才是重点。
3. 事件风暴的场地 只需要一堵足够长的墙和足够大的空间就可以了。墙是用来贴纸的，大空间可以让人四处走动，方便合作。撤掉会议桌和椅子的事件风暴，你会发现参与者们的效率更高。
4. 事件风暴分析的关注点 在领域建模的过程中，我们需要重点关注这类业务的语言和行为。比如某些业务动作或行为（事件）是否会触发下一个业务动作，这个动作（事件）的输入和输出是什么？是谁（实体）发出的什么动作（命令），触发了这个动作（事件）…我们可以从这些暗藏的词汇中，分析出领域模型中的事件、命令和实体等领域对象。
如何用事件风暴构建领域模型 1. 产品愿景 产品愿景的主要目的是对产品顶层价值的设计，使产品目标用户、核心价值、差异化竞争点等信息达成一致，避免产品偏离方向。
在建模之前，项目团队要思考这样两点：
 用户中台到底能够做什么？ 它的业务范围、目标用户、核心价值和愿景，与其它同类产品的差异和优势在哪里？  2. 业务场景分析 场景分析是从用户视角出发的，根据业务流程或用户旅程，采用用例和场景分析，探索领域中的典型场景，找出领域事件、实体和命令等领域对象，支撑领域建模。事件风暴参与者要尽可能地遍历所有业务细节，充分发表意见，不要遗漏业务要点。
场景分析时会产生很多的命令和领域事件。我用蓝色来表示命令，用橙色表示领域事件，用黄色表示补充信息，比如用户信息数据来源于 HR 系统的说明。
3. 领域建模 领域建模时，我们会根据场景分析过程中产生的领域对象，比如命令、事件等之间关系，找出产生命令的实体，分析实体之间的依赖关系组成聚合，为聚合划定限界上下文，建立领域模型以及模型之间的依赖。领域模型利用限界上下文向上可以指导微服务设计，通过聚合向下可以指导聚合根、实体和值对象的设计
第一步：从命令和事件中提取产生这些行为的实体。用绿色贴纸表示实体。通过分析用户中台的命令和事件等行为数据，提取了产生这些行为的用户、账户、认证票据、系统、菜单、岗位和用户日志七个实体。
第二步：根据聚合根的管理性质从七个实体中找出聚合根，比如，用户管理用户相关实体以及值对象，系统可以管理与系统相关的菜单等实体等，可以找出用户和系统等聚合根。然后根据业务依赖和业务内聚原则，将聚合根以及它关联的实体和值对象组合为聚合，比如系统和菜单实体可以组合为“系统功能”聚合。按照上述方法，用户中台就有了系统功能、岗位、用户信息、用户日志、账户和认证票据六个聚合。
第三步：划定限界上下文，根据上下文语义将聚合归类。根据用户域的上下文语境，用户基本信息和用户日志信息这两个聚合共同构成用户信息域，分别管理用户基本信息、用户登录和操作日志。认证票据和账户这两个聚合共同构成认证域，分别实现不同方式的登录和认证。系统功能和岗位这两个聚合共同构成权限域，分别实现系统和菜单管理以及系统的岗位配置。根据业务边界，我们可以将用户中台划分为三个限界上下文：用户信息、认证和权限。
4. 微服务拆分与设计 原则上一个领域模型就可以设计为一个微服务，但由于领域建模时只考虑了业务因素，没有考虑微服务落地时的技术、团队以及运行环境等非业务因素，因此在微服务拆分与设计时，我们不能简单地将领域模型作为拆分微服务的唯一标准，它只能作为微服务拆分的一个重要依据。
微服务的设计还需要考虑服务的粒度、分层、边界划分、依赖关系和集成关系。除了考虑业务职责单一外，我们还需要考虑将敏态与稳态业务的分离、非功能性需求（如弹性伸缩要求、安全性等要求）、团队组织和沟通效率、软件包大小以及技术异构等非业务因素。
代码模型 没有一个统一的代码模型。
微服务目录架构 按照 DDD 分层架构的分层职责来定义，分别为用户接口层、应用层、领域层和基础层。</description>
    </item>
    
    <item>
      <title>DDD进阶-笔记篇</title>
      <link>https://stong1994.github.io/internet/ddd/advance/</link>
      <pubDate>Fri, 29 Jan 2021 23:31:51 +0800</pubDate>
      
      <guid>https://stong1994.github.io/internet/ddd/advance/</guid>
      <description>领域事件 如何识别领域事件 很简单，和刚才讲的定义是强关联的。在做用户旅程或者场景分析时，我们要捕捉业务、需求人员或领域专家口中的关键词：“如果</description>
    </item>
    
    <item>
      <title>DDD基础-笔记篇</title>
      <link>https://stong1994.github.io/internet/ddd/base/</link>
      <pubDate>Fri, 29 Jan 2021 23:07:51 +0800</pubDate>
      
      <guid>https://stong1994.github.io/internet/ddd/base/</guid>
      <description>中台面临的问题：作为中台，需要将通用的可复用的业务能力沉淀到中台业务模型，实现企业级能力复用。因此中台面临的首要问题就是中台领域模型的重构。而中台落地时，依然会面临微服务设计和拆分的问题。
基础 组织架构演进
DDD解决的问题 DDD 核心思想是通过领域驱动设计方法定义领域模型，从而确定业务和应用边界，保证业务模型与代码模型的一致性。
DDD 强调领域模型和微服务设计的一体性，先有领域模型然后才有微服务，而不是脱离领域模型来谈微服务设计。
其次，就是通过战略设计，建立领域模型，划分微服务边界。
最后，通过战术设计，我们会从领域模型转向微服务设计和落地。
战略设计 战略设计主要从业务视角出发，建立业务领域模型，划分领域边界，建立通用语言的限界上下文，限界上下文可以作为微服务设计的参考边界。
三步来划定领域模型和微服务的边界  在事件风暴中梳理业务过程中的用户操作、事件以及外部依赖关系等，根据这些要素梳理出领域实体等领域对象。 根据领域实体之间的业务关联性，将业务紧密相关的实体进行组合形成聚合，同时确定聚合中的聚合根、值对象和实体。在这个图里，聚合之间的边界是第一层边界，它们在同一个微服务实例中运行，这个边界是逻辑边界，所以用虚线表示。 根据业务及语义边界等因素，将一个或者多个聚合划定在一个限界上下文内，形成领域模型。在这个图里，限界上下文之间的边界是第二层边界，这一层边界可能就是未来微服务的边界，不同限界上下文内的领域逻辑被隔离在不同的微服务实例中运行，物理上相互隔离，所以是物理边界，边界之间用实线来表示。  战术设计 战术设计则从技术视角出发，侧重于领域模型的技术实现，完成软件开发和落地，包括：聚合根、实体、值对象、领域服务、应用服务和资源库等代码逻辑的设计和实现。
基本概念   头脑风暴: DDD 领域建模通常采用事件风暴，它通常采用用例分析、场景分析和用户旅程分析等方法，通过头脑风暴列出所有可能的业务行为和事件，然后找出产生这些行为的领域对象，并梳理领域对象之间的关系，找出聚合根，找出与聚合根业务紧密关联的实体和值对象，再将聚合根、实体和值对象组合，构建聚合。
  领域：在研究和解决业务问题时，DDD 会按照一定的规则将业务领域进行细分，当领域细分到一定的程度后，DDD 会将问题范围限定在特定的边界内，在这个边界内建立领域模型，进而用代码实现该领域模型，解决相应的业务问题。简言之，DDD 的领域就是这个边界内要解决的业务问题域。
  子领域：我们把划分出来的多个子领域称为子域，每个子域对应一个更小的问题域或更小的业务范围。
  核心域：决定产品和公司核心竞争力的子域是核心域，它是业务成功的主要因素和公司的核心竞争力。
  通用域：没有太多个性化的诉求，同时被多个子域使用的通用功能子域是通用域。
  支撑域：既不包含决定产品和公司核心竞争力的功能，也不包含通用功能的功能子域。
  通用语言：在事件风暴过程中，通过团队交流达成共识的，能够简单、清晰、准确描述业务涵义和规则的语言就是通用语言。
 通用语言包含术语和用例场景，并且能够直接反映在代码中。通用语言中的名词可以给领域对象命名，如商品、订单等，对应实体对象；而动词则表示一个动作或事件，如商品已下单、订单已付款等，对应领域事件或者命令。
   上下文边界：用来确定语义所在的领域边界。一个上下文边界理论上就可以设计为一个微服务。
  实体：在 DDD 中有这样一类对象，它们拥有唯一标识符，且标识符在历经各种状态变更后仍能保持一致。对这些对象而言，重要的不是其属性，而是其延续性和标识，对象的延续性和标识会跨越甚至超出软件的生命周期。我们把这样的对象称为实体。
  值对象：通过对象属性值来识别的对象，它将多个相关属性组合为一个概念整体。在 DDD 中用来描述领域的特定方面，并且是一个没有标识符的对象，叫作值对象。在领域建模的过程中，值对象可以保证属性归类的清晰和概念的完整性，避免属性零碎。将“省、市、县和街道等属性”拿出来构成一个“地址属性集合”，这个集合就是值对象了
  聚合：聚合就是由业务和逻辑紧密关联的实体和值对象组合而成的，聚合是数据修改和持久化的基本单元，每一个聚合对应一个仓储，实现数据的持久化。
  聚合根：聚合根的主要目的是为了避免由于复杂数据模型缺少统一的业务规则控制，而导致聚合、实体之间数据不一致性的问题。
 如果把聚合比作组织，那聚合根就是这个组织的负责人。聚合根也称为根实体，它不仅是实体，还是聚合的管理者。</description>
    </item>
    
  </channel>
</rss>
