<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>北人</title>
    <link>https://stong1994.github.io/</link>
    <description>Recent content on 北人</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language>
    <lastBuildDate>Sat, 26 Feb 2022 13:03:00 +0800</lastBuildDate><atom:link href="https://stong1994.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>跨越时空的对话——袁了凡与阿德勒</title>
      <link>https://stong1994.github.io/life/dialog/liaofanyuan_adler/</link>
      <pubDate>Sat, 26 Feb 2022 13:03:00 +0800</pubDate>
      
      <guid>https://stong1994.github.io/life/dialog/liaofanyuan_adler/</guid>
      <description>话题——关于命运 中国的大部分人应该都是“信命”的。 现在与长辈聊天时，仍旧会不时听到“这就是命啊”这样的言论。 以前我也同样认可“我们的现在是由</description>
    </item>
    
    <item>
      <title>Manacher算法</title>
      <link>https://stong1994.github.io/internet/algorithm/manacher/</link>
      <pubDate>Sat, 12 Feb 2022 16:32:00 +0800</pubDate>
      
      <guid>https://stong1994.github.io/internet/algorithm/manacher/</guid>
      <description>Manacher算法是什么 Manacher算法俗称马拉车算法，用于解决在一个字符串中找到最长的回文子串问题。
回文串”是一个正读和反读都一样的字符串，如level，noon等都是回文串。
基础思路-中心扩展 为了找到最长的回文串，需要先找到回文串的中心，然后从中心向外扩展。
// 例如我们找到中心处的索引为mid,那么找到以mid为中心的回文串的逻辑代码为： func findPalindrome(s string, mid int) string{ l,r := mid-1, mid+1 for ; l &amp;gt;= 0 &amp;amp;&amp;amp; r &amp;lt; len(s); l,r = l-1, r+1 { if s[l] != s[r] { break } } return s[l+1: r] } 需要注意中心处可能是一个元素（如aba），也可能是两个元素（如abba）。所以上述函数要优化为
func findPalindrome(s string, l, r int) string { for ; l &amp;gt;= 0 &amp;amp;&amp;amp; r &amp;lt; len(s); l,r = l-1, r+1 { if s[l] != s[r] { break } } return s[l+1: r] } 那么一个完整的找最长回文子串的算法为</description>
    </item>
    
    <item>
      <title>2021年阅读书单</title>
      <link>https://stong1994.github.io/book/book_list_2021/</link>
      <pubDate>Wed, 09 Feb 2022 20:11:00 +0800</pubDate>
      
      <guid>https://stong1994.github.io/book/book_list_2021/</guid>
      <description>说明 书籍的分类一直都是一个大难题，尽管我在notion的笔记上对书籍类别打了标签，但学科之间本来就是没有界限的，因此就一股脑放在一起。 书籍会</description>
    </item>
    
    <item>
      <title>2021年个人总结</title>
      <link>https://stong1994.github.io/life/summory_2021/</link>
      <pubDate>Wed, 09 Feb 2022 19:27:00 +0800</pubDate>
      
      <guid>https://stong1994.github.io/life/summory_2021/</guid>
      <description>当我坐着从老家驶向深圳的高铁上时，我意识到这是最后的“年度总结”时间。 在这趟列车达到深圳前，我都有足够的理由安慰自己旧的一年还未结束。对我来</description>
    </item>
    
    <item>
      <title>KMP算法</title>
      <link>https://stong1994.github.io/internet/algorithm/kmp/</link>
      <pubDate>Fri, 28 Jan 2022 16:32:00 +0800</pubDate>
      
      <guid>https://stong1994.github.io/internet/algorithm/kmp/</guid>
      <description>背景 在做LeetCode第572题——另一颗树的子树时，我看到题解上说可以用KMP算法来解决。虽然以前了解过KMP算法，但是遇到问题时还是对算法的思路、如何实现一头雾水，因此写篇文章总结下。
KMP是什么 KMP是由三位作者的名称首字母组成的单词。KMP的目的是解决子串查找问题。
KMP演化 如果只看KMP算法的代码，会很难理解，因此我们从头来演化KMP的思路。
既然KMP算法要解决的是子串查找问题，那我们就从最无脑的暴力破解算法说起。在此之前，我们要规定几个概念。
基础概念  模式字符串：要匹配的字符串模板。通常是在初始化时处理的数据。 匹配字符串：要根据模式字符串去匹配的目的字符串。通常是输入数据。往往需要找到和模式字符串相同的子串的首字母索引——即在匹配字符串中找到模式字符串。  最无脑的算法 把匹配字符串看做是一把完整的尺子，把模式字符串看做是一把残尺。尺子上的刻度数字都是随机数字。
固定好完整的尺子，将残尺从完整的尺子的第一个刻度处开始比较，如果不匹配就把残尺往后移动一位。直到找到匹配的位置。
func violentSearchSubStr(txt, pat string) int { for i := 0; i &amp;lt; len(txt) - len(pat)+1; i++ { j := 0 for ; j &amp;lt; len(pat); j++ { if txt[i+j] != pat[j] { break } } if j == len(pat) { return i } } return -1 } 利用已有的经验——部分匹配表PMT 在“最无脑的算法”中，每次匹配失败都会将残尺往后移动一位。假设残尺上有10个数字，匹配失败时是在匹配第10个数字时失败，那么这10次匹配经验就浪费掉了。
模式字符串的前四个数字为3153，最后匹配的匹配字符串的四个字符串也是3153，因此，我们可以直接将残尺的3153和完整尺的3153对齐，即可以直接移动六位。
显然，利用历史经验一次性移动六位要比移动一位的效率高很多。那么如何利用这些匹配经验，将残尺多移动几位？
于是问题转换为：假设残尺需要移动的位数为M，移动后残尺的前N位能够匹配，如何利用已知条件求出最大的M？
大佬们为此设计了部分匹配表（Partial Match Table）：PMT是一个数组，长度与模式字符串相同。每个元素对应的是其在模式字符串对应的字符串前缀中前后对称的字符的个数。例如：对于第4个元素来说，其对应的模式字符串前缀为3153，其前后对称的字符为3，个数为1；对于第5个元素来说，其对应的模式字符串的前缀为31531，其前后对称的字符为3和1，个数为2，因此可以得到PMT：</description>
    </item>
    
    <item>
      <title>理解事务：InnoDB的ACID</title>
      <link>https://stong1994.github.io/internet/mysql/acid/</link>
      <pubDate>Sun, 16 Jan 2022 17:05:00 +0800</pubDate>
      
      <guid>https://stong1994.github.io/internet/mysql/acid/</guid>
      <description>事务对于数据库而言是非常重要的，事务能够保证我们的软件世界是稳定的——从一个状态到另外一个状态是符合人们预期的。而为了能够保证一个事件在任何情况下都能符合人们的预期，我们总结出事务需要满足四个特性：原子性、一致性、隔离性、持久性。
每种数据库对于事务的实现都不同，有的数据库，如Redis，没有实现所有的事务特性，而目前比较火的分布式数据库，也有自己的实现特性——BASE。但理解事务的特性仍是软件开发行业从业者的基础素质。
本篇会以InnoDB为例，来探究它是如何实现事务的。
事务id的生成 事务id的生成规则与row_id的生成规则不能说相似，只能说一模一样。
 服务器在内存中维护一个全局变量，每当需要为某个事务分配事务id时，获取这个变量作为row_id的值，并把这个全局变量自增1 每当全局变量的值变为256的倍数时，就会将该变量写入系统表空间中 当系统启动时，将系统表空间中的该变量加上256加载到内存中（加256是为了确保内存中的值一定比记录中已存在的事务id值大）  原子性（Atomicity）  一个事务内的执行语句要么全执行，要么都不执行。可以理解为一个事务内的多个事件，如果有一个事件发生异常，就要回退到第一个事件发生前的状态。
 原子性要求我们可以对执行事务过程中改变的数据进行回滚，而为了实现回滚，InnoDB使用了undo log。
undo log 一个索引除了会产生叶子结点段和非叶子结点段之外，还会产生回滚段。我们的undo log就是存放在回滚段中。
对于每条记录，都会存在两个隐藏列：trx_id和roll_pointer。每次新增undo log时，会在新纪录上更新roll_pointer，指向新的undo log，而undo log也会记录旧记录上的roll_pointer，这样，以新纪录开始，与仍存在的旧记录形成了一条版本链。undo log上的旧记录可能不会记录所有的数据，如更新操作产生的日志就是只记录被更新的字段，但是通过遍历版本链就能找到旧记录的所有字段。
向表中插入/更新/删除一条记录时，需要对聚簇索引和所有二级索引都进行插入/更新/删除，但是在记录undo log时，我们只需要针对聚簇索引来记录。聚簇索引和二级索引都是一一对应的，在回滚时，根据主键信息对所有的二级索引都进行回滚即可。所以，只有聚簇索引才会存在回滚段。
对于插入操作 插入操作的回滚操作就是删除操作，因此，在undo log中记录插入记录的主键即可。
对于删除操作 删除操作的逆操作插入操作，按道理来说，undo log中会记录被删除的数据，但是InnoDB没有这样做。因为如果数据被删了，那么“其他人”就看不到了，先于这个事务执行的事务就可能会产生不可重复读或者幻读。
InnoDB中的实现是这样：
 第一阶段，将这个记录的deleted_flag（每个记录都有的隐藏列）标识为1，这就意味着这条记录正在删除中。同时，在undo log中需要记录索引各列的信息，用于后续的purge操作。 第二阶段，在事务提交后，会有专门的线程来把这条记录删除掉——把这条记录从正常记录链表中删除，并加入到垃圾链表中  对于更新操作 更新操作需要分为两种情况：更新主键、不更新主键
不更新主键 如果不更新主键，并且更新前后这条记录的各个字段占用的空间都不变，那么直接将变更的旧字段写到undo log即可。
如果更新后字段占用的空间有变化，那么就要删除这条旧记录，并将其放入“垃圾链表”中（并不是标记删除），如果新记录占用的空间小于旧记录，则可以“复用”旧记录的空间，否则需要重新申请一块空间来存放新记录。
undo log会记录更新的列的旧数据，以供回滚。
更新主键 如果要更新主键，那么就相当于先进行删除操作，再进行插入操作。即先对旧记录进行标记删除，再插入新数据，同时产生两条undo log。
undo log在崩溃恢复时的作用 服务器在崩溃后的恢复过程中，首先根据redo log将各个页面的数据恢复到之前的状态，但是有些没有提交的redo log可能已经被刷盘，因此未提交的事务修改过的页面也被恢复了。这时需要把这些页面回滚掉。
通过系统表空间定位到回滚段的位置，并找到状态为TRX_UNDO_ACTIVE的undo log链表，这意味着存在活跃的事务正在向这个undo log链表写入undo log，找到对应的事务id，并将其做出的修改全部回滚掉。
一致性（Consistency） 关于一致性，似乎没有统一的说法，有的说ACID中的C是用来凑数的，一致性是事务要达到的目的，而不是事务特性；有的说一致性就是数据库对于数据的约束，如非空、唯一等；有的说一致性要由业务逻辑的程序来维持。不用纠结这些。
另外，区别于分布式数据库中的最终一致性，InnoDB中的一致性指的是强一致性。
隔离性（Isolation）  事务之间应该是隔离的、互不影响的。
 业内的隔离性划分（非InnoDB） 四种隔离问题  脏写：一个事务修改了另一个未提交的事务的数据 脏读：一个事务读取了另一个未提交的事务修改后的数据 不可重复读：一个事务两次读取同一条记录的数据不同，因为被另一个事务修改 幻读：一个事务两次读取的范围数据不同，因为被另一个事务进行了插入/更新操作  四种隔离级别  读未提交：只解决脏写问题 读已提交：解决脏写、脏读问题 可重复读：解决脏写、脏读、不可重复度问题 串行化：解决全部四个问题  三种锁  排它锁：对于同一条记录，只有一个事务能够修改 共享锁：对于同一条记录，多个事务都能读取，但不允许修改 范围锁：一个范围内的记录的共享锁  他们之间的关系    使用的锁 隔离问题 隔离级别     不用锁 未解决：脏写、脏读、不可重复度、幻读 无，脏写问题是必须要避免的   排它锁 只解决脏写 读未提交   排它锁+（读完就释放的）共享锁 解决脏写、脏读 读已提交   排它锁+（事务执行完才释放的）共享锁 解决脏写、脏读、不可重复读 可重复读   排它锁+共享锁+范围锁 解决脏写、脏读、不可重复读、幻读 串行化    由上可以看出，是由于使用的锁不同，进而产生了隔离问题、隔离级别！</description>
    </item>
    
    <item>
      <title>解决问题时的短路问题</title>
      <link>https://stong1994.github.io/life/short_circuit_when_solve_problem/</link>
      <pubDate>Sun, 09 Jan 2022 17:25:00 +0800</pubDate>
      
      <guid>https://stong1994.github.io/life/short_circuit_when_solve_problem/</guid>
      <description>场景描述 前一阵子做企业微信的组织和人员同步，上线后本来是风平浪静，直到有天接到一个工单：有家企业的部分员工的部门没有同步过去。 工单描述的有点</description>
    </item>
    
    <item>
      <title>《洞见》</title>
      <link>https://stong1994.github.io/book/philosophy/why_buddhism_is_true/</link>
      <pubDate>Tue, 04 Jan 2022 16:24:00 +0800</pubDate>
      
      <guid>https://stong1994.github.io/book/philosophy/why_buddhism_is_true/</guid>
      <description>作者：罗伯特·赖特 关于书名 最早看到这本书是李录在《文明、现代化、价值投资与中国》一书中，作为推荐书籍介绍的。当时给我留下了很深刻的印象，大半</description>
    </item>
    
    <item>
      <title>塔勒布四部曲之《黑天鹅》</title>
      <link>https://stong1994.github.io/book/philosophy/taleb_four_book/</link>
      <pubDate>Tue, 04 Jan 2022 16:24:00 +0800</pubDate>
      
      <guid>https://stong1994.github.io/book/philosophy/taleb_four_book/</guid>
      <description>塔勒布写作风格很特别，他不会着眼于书中的核心思想，而是像闲聊般的把他想说的内容都放到书中，同时伴随着对某些人的不拘一格的嘲讽。 塔勒布四部曲 《</description>
    </item>
    
    <item>
      <title>InnoDB存储引擎的物理结构</title>
      <link>https://stong1994.github.io/internet/mysql/InnoDB_struct/</link>
      <pubDate>Mon, 03 Jan 2022 13:32:00 +0800</pubDate>
      
      <guid>https://stong1994.github.io/internet/mysql/InnoDB_struct/</guid>
      <description>要了解使用InnoDB存储引擎进行CRUD时发生了什么，怎么也绕不过其物理结构，于是在这里记录下。
只记录关键信息，能支持理解CRUD与事务特性即可
关于取舍 作为一个通用的数据存储方案，需要考虑很多问题，这些问题包括如何占用更少的磁盘、内存，如何提高CRUD的速度，如何保证数据的一致性等待。
作为一个通用的方案，就一定要对这些问题进行取舍，而在InnoDB的设计中，可以看到其**优先考虑减少磁盘随机IO，然后是占用更少的磁盘空间。**而为了支持事务的特性，而引入了undo log和redo log等组件，导致整体设计上的复杂度很高。看完InnoDB的设计，再对比redis的设计，就能感慨redis的简洁，但是这不代表redis的设计更优雅，每个组件的定位不同，使用场景也不同，设计上自然也就不同。
磁盘 页 页是InnoDB最基本的存储单位。
页由File Header、Page Header、Infimum+Supremum、UserRecords、Free Space、Page Directory、File Trailer组成。
File Header File Header通用于各种类型的页，用户记录页号、页类型、校验和、所属表空间、上下页的页号等。
这些页通过上下页的页号构建了一个双向链表，无需这些页在物理上真正连着。
File Trailer File Trailer由8字节组成。
前4个字节表示页的校验和，此校验和应该与File Header的校验和相等，如果不等，说明刷新页的过程被中断了，如断电。
后4个字节表示页面最后修改时对应的LSN的后4字节，正常情况下与File Header的Fil_PAGE_LSN的后4字节相同。也是用来校验页的完整性的。
Page Header Page Header用来存储页的状态，如存储的记录条数、槽的数量、Free Space在页面的地址偏移量等。
User Record 和 Free Space User Record和Free Space组成了页的剩余部分，每次插入数据时，都会从Free Space申请一部分空间划到User Record中。
在User Record中是一条条紧密相邻的记录。记录中包括一些控制信息，比如记录是否被删除、下一条记录的相对位置（next_record）等。
通过next_record，页中的记录组成了一个单向链表，链表是根据主键大小由小到大按顺序连接的，因此为了更快的找到最大值和最小值，页中又引入了两个虚拟记录——最大记录（Supremum）和最小记录(Infimum)。
Page Directory 如果没有页目录，那么查找一条数据只能遍历查找，所以InnoDB引入了页目录。
页目录只记录每组记录的最大值，这些最大值在页目录中被称为槽(Slot)，槽在页目录中也是从小到大按顺序存放的。
记录的分组规则：
 最开始时只有两个虚拟记录Supremum和Infimum，各自占一个槽。 插入数据时，找到比插入数据大的第一个槽（二分法），将其插入到这个组中。  如果插入后该组的记录数大于8个，那么就将这个槽拆分成两个组，并在页目录中增加一个槽，其中小槽中分配到的记录数为5条，大槽中分配到的记录数为4条。    由上可知分组的记录特色：
 第一个槽Infimum只有其自身一条记录 最后一个槽Supremum记录数为1-8条 中间槽的记录数为4-8条  在页中查找一条记录时：
 通过二分法确定该记录所在的槽（先找到比该记录主键大的第一个槽，再找到上一个槽，根据其next_record找到记录所在槽的最小记录地址） 通过next_record遍历该组中的各个记录  索引 在查询数据时，首先需要定位数据存在于哪个页时，虽然通过遍历数据页组成的链表查询到，但性能太差，因此引入了索引。</description>
    </item>
    
    <item>
      <title>《关键路径》</title>
      <link>https://stong1994.github.io/book/philosophy/critical_path/</link>
      <pubDate>Sun, 02 Jan 2022 16:24:00 +0800</pubDate>
      
      <guid>https://stong1994.github.io/book/philosophy/critical_path/</guid>
      <description>作者：理查德·巴克敏斯特·富勒 总览 富勒仅以400页书籍描述了其宏大的世界观——实现人类的可持续发展、解决近邻宇宙的可再生问题。 富勒在32岁时</description>
    </item>
    
    <item>
      <title>和时间赛跑</title>
      <link>https://stong1994.github.io/life/run_with_time/</link>
      <pubDate>Sun, 19 Dec 2021 23:39:00 +0800</pubDate>
      
      <guid>https://stong1994.github.io/life/run_with_time/</guid>
      <description>高中的时候琦哥跟我说：其实我要求并不高，只要有人跟我表白我就答应。 这句话我一直想不明白，要知道像琦哥这种学习好、长得帅、性格好的人，那是校草</description>
    </item>
    
    <item>
      <title>《HR&#43;三支柱：人力资源管理转型升级与实践创新》</title>
      <link>https://stong1994.github.io/book/improve/hr_three-pillar-mode/</link>
      <pubDate>Fri, 17 Dec 2021 13:57:00 +0800</pubDate>
      
      <guid>https://stong1994.github.io/book/improve/hr_three-pillar-mode/</guid>
      <description>哈蒙兹：人力资源从业者的四宗罪 智力一般 最优秀、最聪明的人都不进入人力资源行业 追求效率大过创造价值 HR总是强调做了什么，而非创造了什么结果 代表</description>
    </item>
    
    <item>
      <title>《菊与刀》</title>
      <link>https://stong1994.github.io/book/anthropology/TheChrysanthemumAndTheSword/</link>
      <pubDate>Sun, 12 Dec 2021 21:36:00 +0800</pubDate>
      
      <guid>https://stong1994.github.io/book/anthropology/TheChrysanthemumAndTheSword/</guid>
      <description>《菊与刀》是鲁思·本尼迪克特于1945年写的，记录了日本人文社会的特点。对于想要了解日本文化的人来说，这是一本必读书籍！ 70多年过去了，也许</description>
    </item>
    
    <item>
      <title>如何写没有bug的代码</title>
      <link>https://stong1994.github.io/internet/how_to_code_without_bug/</link>
      <pubDate>Sat, 04 Dec 2021 23:31:51 +0800</pubDate>
      
      <guid>https://stong1994.github.io/internet/how_to_code_without_bug/</guid>
      <description>作为一名程序员，bug就是我们生活的一部分。 一听到有bug，绝大分程序员的血压会立马上升，紧接着心脏跳动加快，然后带着一丝侥幸的期待着这是个</description>
    </item>
    
    <item>
      <title>简述redis的基本实现</title>
      <link>https://stong1994.github.io/internet/depth/redis_base_design/</link>
      <pubDate>Mon, 22 Nov 2021 16:05:00 +0800</pubDate>
      
      <guid>https://stong1994.github.io/internet/depth/redis_base_design/</guid>
      <description>很久之前就看过redis的基本设计与实现，但是每次都会忘掉。
前几天又看了一遍，但是最近回顾的时候又忘了。。。
俗话说好记性不如烂笔头，因此写在这里来加深记忆。
文中会将数据类型的实现与go中的实现进行对比，如有理解错误的地方，望指出
五个基本数据类型 string  go中的string：在go中，string就是一组字节，且是不可变的。可以视作字节数组。
 redis中的字符串对象的编码可以是int、raw或embstr。
如果保存的对象是整数且可以用long类型来表示，那么就保存为整数，编码为int。
如果保存的对象是字符串且长度小于等于32字节，那么会使用embstr的编码来保存。
如果保存的对象是字符串且长度大于32字节，那么会使用embstr的编码来保存，且存储在SDS中。
embstr是专门用来保存短字符串的一种优化编码方式，与raw的区别在于对于redisObject和sdshdr（redisObject是redis对象中的一个属性，sdshdr是SDS的实现），embstr只需一次内存分配，而raw需要两次。
SDS 简单动态字符串（SDS）组成：
 buf: 字节数组 len: 字符串长度（即buf数组中已使用的字节数量） free: buf数组中未使用的字节数量  SDS遵循C字符串以空字符结尾的惯例，保存空字符串的1字节空间不计算在SDS的属性中。
空间预分配策略：修改之后的SDS长度小于1M，那么程序会分配同样大小的预留空间，即len=free；如果修改之后的SDS长度大于1M，那么程序会分配1M的预留空间。
空间惰性释放策略：SDS中的字符串长度减小时，并不直接释放空间，而是增大free，可供未来使用，避免频繁释放/分配空间。
list  go中的slice
构成：由三个属性构成：长度、容量、底层数组。
扩容策略：当容量小于1024时，每次扩容为原来容量的一倍；否则扩容1/4
缩容策略：无
 当list中元素的字符串长度都小于64字节且元素数量小于512时，使用压缩列表实现，否则使用双端链表实现。
双端链表 双端链表有如下几个属性：
 表头节点 表尾结点 节点长度 节点复制函数 节点释放函数 节点值对比函数  节点有如下属性：
  前置节点地址
  后置节点地址
  节点值
  压缩列表 压缩列表包含的属性：
 整个压缩列表占用的字节数 计算列表尾结点距离压缩列表的起始地址有多少字节 记录压缩列表包含的节点的数量（当总数大于65535时，这个字段失效，需要遍历整个压缩列表才能计算出来） 列表节点数组（每个节点可以保存为一个字节数组或者整数）  列表节点包含的属性：
 上一个节点的长度 编码类型与长度 节点内容  压缩列表的优点就是节省内存，缺点就是增加、删除、更新可能会造成“连锁更新”，因此只有在包含少量元素时才使用。</description>
    </item>
    
    <item>
      <title>以真实经历谈分层</title>
      <link>https://stong1994.github.io/internet/depth/layer/</link>
      <pubDate>Sat, 20 Nov 2021 13:20:00 +0800</pubDate>
      
      <guid>https://stong1994.github.io/internet/depth/layer/</guid>
      <description>笔者在工作过程中遇到了一些分层相关的问题，于是将问题和想法记录下来，以供未来回顾。
提出问题  什么是分层 为什么要分层 怎样做分层  什么是分层 这是一个很简单的问题。
这也是一个很复杂的问题。
简单之处在于每个人都能做出回答，复杂之处在于这其实是个通用问题。
通用问题是啥？百度百科上是没有这个词条的，因为我不知道这类问题如何划分，所以随便造了个词，或者称为底层逻辑问题更好理解些？
程序员当然知道有哪些分层：网络有分层、操作系统有分层、项目有分层、代码有分层等等。
但生活中的分层要更多。
 每天早上吃的鸡蛋有分层：蛋壳、蛋白、蛋黄 上班路上两边的树木有分层：树根、树干、树冠、树叶，或者将其拦腰斩断，能看到层次分明的年轮 坐电梯时可能更能体会到分层——每层楼都是一层。 进入公司，销售部、行政部、研发部等等也在分层 连我们人体本身也满是分层：上半身、下半身、头、胳膊、脚，或者皮肤、脂肪、血液、骨骼、神经等等  分层是这个世界的基本规则之一。
思维的发散就到此为止吧，因为我已经发现没有办法直面我们最初的三个问题了。
所以让我们来简化下问题——将问题的讨论范围限制在代码内。
对于什么是分层——我先给出我的答案——分层就是对代码按照某种规则进行切分。
至于为什么是这个答案，下面会讲。
为什么要分层 我们先来回顾下分层的演进。
最早的分层是什么呢，那一定是没有分层。当我们打印出“hello world&amp;quot;时，我们是没有分层的。
让我们继续写代码。我可能要在前端展示一些文字，这些文字可能存储在数据库中。如果仅仅是这样的话，我们很可能还是没有分层——功能实在是太简单了。
直到有一天，我们写了上千行的代码，突然发现代码已经很难维护了，因为数据模型、业务逻辑、前端代码等都混在一起，于是我们本能的开始分层。于是一个伟大的概念产生了——MVC。
MVC最早据说是起源于桌面端开发，M代表数据层，V代表UI层，C代码控制层，通过分离这三层，我们的代码已经是很清晰了。
但是该死的产品经理还在没完没了的增加那些不知道有什么用的功能。
于是代码开发者发现三层不够用，于是把前端和后端代码进行了隔离，也就是前后端分离。后端将已有的两层扩展为三层——控制层-逻辑层-数据层（controller-service-model）。那么前端呢？前端都分出去了，我们就不管了。
 这里有个逻辑要叙述下。有些人认为是ajax这类技术的产生才导致了前后端分离。这种想法属实是本末倒置了，任何技术的产生都来源于需求！
 我对于controller-service-model这种分层可谓是异常熟悉，因为就在我大学实习的时候，就用的这种分层。当时用得是java的SSM框架，三个框架正好对应这三层（java好像搞啥都是一整套？）。这几个框架让我深受贫血模型的影响，即使我后来不写Java了。
时代在发展，软件的用户越来越多，功能越来越复杂，开发人员越来越多。代码也越来越臃肿。
于是某个大佬发明了微服务的概念，再然后某个大佬发明了中台的概念。
于是我们不仅有前后端的分层，还有后端与后端的分层——前台、中台、支撑的分层。
回到我们的问题——为什么要分层——答案应该已经很明确了，就是为了解决代码的臃肿问题，让代码更清晰！
怎样做分层 服务分层  现状：目前公司内有很多中台仅仅是对数据库的CRUD的封装（看起来就像是封装了一个使用http做传输的ORM框架），业务逻辑仍集中在前台。这种中台没有任何意义，似乎只是为了分层而分层，或者说为了做中台而分层。进一步的原因就是设计者对中台缺乏认知。
 目前我们的项目存在两种分层方式：按功能划分与按业务划分。
以报表功能举例：我们在多种场景中都需要报表功能，如人事报表、招聘报表。这些报表都有自己的业务逻辑，不能进行统一处理，但是都需要订阅功能，且都存在业务逻辑：当用户删除报表时，需要同时删除用户对该报表的订阅（该功能在下文用功能A标识）。
按功能划分 根据功能的性质划分，此时订阅功能和报表功能为同等级功能。
此时会存在：报表中台、报表前台、订阅中台、订阅前台。
功能A应在报表前台来实现。
按业务划分 按照业务来划分，此时订阅功能应被视为报表的附属功能。
此时会存在：招聘报表中台、招聘报表前台、人事报表中台、人事报表前台。
功能A应在招聘报表中台和人事报表中台分别实现。
划分手段 上边直接说了结论，那么这样划分的依据是什么？
首先必须要分为中台和前台：中台作为业务的聚合，而前台作为对前端的适配。这样能保证业务逻辑的内聚，使中台专注于自己的业务，避免易变的产品需求对业务核心代码的侵蚀。
其次一定要让服务有明确的边界。设计者不能凭感觉来划分服务，一定要有自己的方法论作为指导基础。如果只凭感觉来划分，最终的结果就是服务之间没有边界，导致中台服务冗余了大量不属于自己领域内的代码。
所以不管是按功能划分还是按业务划分又或者有其他划分方法，总之设计者一定要有自己的划分方法论。
代码分层  现状：目前公司内大量项目的代码结构为controller+business+service。business做业务逻辑，service做服务实现。换句话说，就是将以前的service层改名为business，以前的model改名为service。这种改变的逻辑是：微服务时代需要大量调用其他服务，model不具有此含义，因此需要将model改名为service，用service来处理调用其他服务的逻辑。
这种结构在实际开发中面临一个非常严重的问题——business和service的边界模糊——导致service层的代码和business层代码混在一起——导致本就复杂的业务层代码更加复杂且难以理解。
 如何解决business和service的边界模糊问题 边界模糊的原因1：词汇描述能力不足。我们一般使用service来写业务逻辑，现在换用了business，但是仍保留service层来做服务调用，这增加了开发者对service和business语义上的模糊。另外，从读者的角度来看，这种命名会让人十分疑惑。</description>
    </item>
    
    <item>
      <title>琦哥</title>
      <link>https://stong1994.github.io/life/qi/</link>
      <pubDate>Sun, 14 Nov 2021 18:07:00 +0800</pubDate>
      
      <guid>https://stong1994.github.io/life/qi/</guid>
      <description>如何证明自己存在过？ 年轻时候的我决定要干大事，要成就一番丰功伟绩来让我的子孙们铭记他们这个伟大的先祖！ 可惜他们这个先祖并不争气，到现在还只是</description>
    </item>
    
    <item>
      <title>《深度工作》</title>
      <link>https://stong1994.github.io/book/improve/deep_work/</link>
      <pubDate>Thu, 07 Oct 2021 20:20:00 +0800</pubDate>
      
      <guid>https://stong1994.github.io/book/improve/deep_work/</guid>
      <description>在十一小长假的最后一天，我终于翻开了这本放在书包里很多天的《深度工作》。 本来打算今天只看一半，没想到一口气花了约三个小时，把这本240页的书</description>
    </item>
    
    <item>
      <title>查询、插入、删除、更新一条MySQL记录都经历了什么</title>
      <link>https://stong1994.github.io/internet/MySQL/curd/</link>
      <pubDate>Wed, 06 Oct 2021 17:05:00 +0800</pubDate>
      
      <guid>https://stong1994.github.io/internet/MySQL/curd/</guid>
      <description>一直对MySQL这个黑盒子是如何运行的不甚清楚，因此在这里总结下。
先来了解下MySQL体系架构。
MySQL体系架构 图片来自: https://segmentfault.com/a/1190000039693313
以上图为对照，MySQL的查询会经历大致以下过程：
 客户端与服务端建立连接 查询缓存 将请求的SQL进行解析，并进行语法校验 通过优化器来优化SQL，生成执行计划 选择对应的存储引擎来执行计划，获取数据 向客户端返回查询结果  那么我们就来分别看看这几步都做了哪些事情。
建立连接 客户端与服务端的连接本质上是进程间的通信，进程之间的通信方式有：管道、命名管道、命名字、TCP/IP套接字、UNIX域套接字。我们只讨论最常见的TCP/IP套接字。
mysql -h 127.0.0.1 -u root -p 连接时会查询mysql.user表进行权限校验。
 MySQL的通信协议是半双工的——在任意时刻，要么客户端向服务端发送数据，要么服务端向客户端发送数据。
 查询缓存 如果操作为查询，并且MySQL服务器开启了查询缓存，那么MySQL服务器会对sql进行缓存命中。
这个缓存是由大小写敏感的哈希查找实现的，对sql的任何改动都会导致不能命中缓存。
解析sql 在这一步会校验sql是否符合语法，并将sql解析为token。
查询优化 MySQL使用基于成本的优化器。成本分为IO成本和CPU成本，MySQL会定义每种操作对应的代价。大致流程为：
 根据搜索条件，找出所有可能使用的索引 计算全表扫描的代价 计算使用不同索引执行查询的代价 对比各种方案，选择成本最低的那个  执行语句 只讨论增删改查。
读取记录的过程 缓存都做了什么 InnoDB是以页为单位进行磁盘IO的，如果每次读取都要从磁盘读取，那么性能会很差。因此引入了缓存池——BufferPool，而从磁盘中加载到缓冲池中的页我们称为缓冲页。
每次读取数据页时，都从一个哈希表（key为表空间号+页号，value为控制块）中定位到缓冲页对应的控制块，如果不存在，则从磁盘进行读取，如果存在，则直接读取缓存。
每次从磁盘读取数据页时，都会在Buffer Pool中的free链表中获取空闲页，并填充缓冲页对应的控制块（我们需要这个结构来快速定位到目标缓冲页）。
InnoDB还引入了LRU链表来淘汰最近最少使用的缓冲页（参考InnoDB中的LRU链表）。
在聚簇索引中定位一条记录 通过索引页定位数据页  在索引页中，通过二分法定位记录所在的槽，这个槽对应着索引所在的索引记录组。（索引记录被分成多组，每组的最小值存入Page Directory，称为槽slot） 在索引记录组中通过next_record字段来遍历整个组，找到记录所在的索引页数据（主键+页号） 通过页号找到下一层树的目标索引页 重复上述3个步骤，直到找到最后一层树——即数据页  在数据页中定位目标记录  在数据页中找到Page Directory，通过二分法定位目标记录所在的槽（记录被分成多组，每组的最大值（思考为什么是最大值而不是最小值）存入Page Directory，称为槽slot） 通过Page Directory找到上一个槽，其对应的记录为该组的最大值，然后通过next_record来找到目的槽中的最小值，接着通过next_record来遍历整个目的组找到目标记录。  在二级索引中定位一条记录 定位方式同聚簇索引相同，不同之处在于二级索引中的数据页存储的是主键而不是完整的记录，因此需要通过主键进行回表查询。
锁和事务 事务中不加锁的读 在事务中，如果读操作没有加锁，那么会生成一个ReadView来保证每次读到事务开始前已提交的数据（可重复读的隔离级别下每个事务中的多次读取复用同一个ReadView，读已提交的隔离界别下每次读取都会生成一个新的ReadView）</description>
    </item>
    
    <item>
      <title>谈代码规范、思想</title>
      <link>https://stong1994.github.io/internet/depth/code_thought/</link>
      <pubDate>Wed, 06 Oct 2021 17:05:00 +0800</pubDate>
      
      <guid>https://stong1994.github.io/internet/depth/code_thought/</guid>
      <description>谈起代码设计规范，人们总会说出SOLID、KISS、DRY等等专业词汇。
为了易于人们记忆，这些专业词汇都是由其英文单词首字母拼接起来的，如KEEP IT SIMPLE 、STUPID、DONT TRY YOURSELF。
我们当然也能理解这些设计规范的意思——毕竟有那么多的博客、文章。
然而有多少人能真正使用这些设计规范呢？相比于知道它们的人数，实际使用过的人数应该很少。
 知易行难。知行不能统一，还是不知。
 大部分人在刚入行时写的代码都“too young too simple”。很幸运的是我在刚入行时就被一位大佬告知：如果你哪天领悟了SOLID原则，就能写出好代码。
被告知之前，我有看过SOLID原则，被告知当天，我又看了一遍SOLID原则，被告知以后的以后，我也会不时的看下SOLID原则。但是我一直都没能彻底了解这个原则——我只是看懂了那些博客说的是什么，但是究竟要如何使用SOLID原则还是一头雾水。
也许这些原则就不是用来指导人们如何使用的，而是告诉人们好的代码应该是怎样的。
程序猿也是在不断进化的。
刚入行的小伙子是“鲁莽”的，他们的眼里好像只能看到“需求”，他们会飞快地将功能实现。这时候的代码没有遵循任何的设计原则，代码混乱，很容易产生bug。而且解决这些bug需要很长的时间，因为他们的代码在实现功能时没有体现业务逻辑。理清为什么这样写要耗费人不少耐心。如果这些代码被一些有强迫症的人看到，一定会给它重构一遍。
有些工作经验的开发者会学习业内比较有名的技术、思想，就像现在的中台、DDD、TDD等。当他们照猫画虎得将这些用到实际项目中时，另外一些没学过这些技术的人会对这些东西表示怀疑——这些东西似乎让代码变得更加复杂，且没看到任何收益。
经过一段时间的怀疑人生后，对技术照猫画虎的人们开始否定这些技术，认为这些技术是徒有其表。
当开发者的经验积累到一定程度后，会开始反思当前的架构是否合理，于是尝试对其进行改进。然后就会突然发现，他竟然运用到了这些设计原则、思想。
那么以后会怎样呢？</description>
    </item>
    
    <item>
      <title>异地多活</title>
      <link>https://stong1994.github.io/internet/design/dboat/</link>
      <pubDate>Mon, 04 Oct 2021 22:32:00 +0800</pubDate>
      
      <guid>https://stong1994.github.io/internet/design/dboat/</guid>
      <description>背景 随着用户的日益增多，系统的质量问题越来越突出。
想象一下：用户正在使用软件，突然软件崩溃了、不能用了，这时候用户肯定要理(ma)解(niang)的。如果一年只崩溃一两次还好（当然，如飞机、火车运行所需要的软件是绝对不能出问题的），如果每隔几天就来这么一下，那么用户可能就要寻找替代品了。2B的产品更是如此（业内通常使用SLA来描述可靠性，也就是大佬们常说的4个9、5个9）。
提升服务质量的手段有很多，如：
  良好的代码风格、积极的code review、完善的自动化测试——在根上减少问题出现的可能性
  合理的监控、报警、预警——保证第一时间内得到通知甚至提前预知风险
  科学的熔断策略——减小一个低质量的服务造成全体系统崩溃的风险
  完善的链路追踪、日志系统——提高解决问题的速度
  善用灰度网关——减少重构系统带来的风险以及损失
  。。。
  尽管目前的手段众多，但是如果一个地区发生了“黑天鹅”事件，如没有预警的停电、地震、海啸，又碰巧这就是我们的服务器所在地，那么上述手段也是无能为力。
所以我们就需要更强大的容灾方案——异地多活。
目标 实现两地三中心方案。
什么是两地三中心？就是在两个区域部署三套服务——一个区域一套，另外一个区域两套。大部分两地三中心是在同城双活的基础上，增加了异地灾备数据中心。而对我们来说，其实就是实现的多区域同步设计方案，只是在实施上是两地三中心。
为什么不是三地三中心？因为城市之间要通过光缆来传输数据，而这是一笔很大的开销。
功能列表：
 用户“就近访问” 区域之间的数据同步 一个区域的服务器宕机后，流量自动打到其他区域 等  仅看这个功能列表，很多细节都很模糊（不是模糊，是根本就没有），我们先看设计方案，然后再把剩余的细节问题解决。
设计方案 两区域间单向的数据流 上图是区域之间数据的单向流动。
 数据库的同步组件选择了阿里开源的canal，它会模拟从服务器来获取数据库的binlog canal支持tcp、kafka、rocketmq三种同步方式，我们选择kafka 发送端：主动发起同步的区域从kafka中获取到数据，然后发往被同步的区域 接收端：被同步的区域接收数据的服务即为接收端，接收到数据后会放到kafka中。这里kafka的作用是削峰与暂时的持久化。 回放端：从第四步中的kafka中获取数据，解析为sql，并执行，完成数据的回放  以上步骤解决了两个区域之间的单向同步
两区域间双向的数据流 跟前一张图相比，只是进行了“镜像复制”，逻辑没有增加。
但是我们发现了数据回环——即从A区域的数据同步到B区域之后，又回到了A区域。如何打断数据回环？
一般来说，我们以“就近原则”为准，能在B区域打断就不要在A区域打断，这样至少能减少数据传输。
我们能控制得只有接收端、回放端和发送端，并且需要在入库之前打上标记，入库拿到数据之后进行过滤。根据“就近原则”，我们在回放端标记数据，在发送端进行数据过滤。具体方案如下：
将数据信息记录到redis的hash中，key为`replay:{数据库名}:{表名}`， field和value规则如下： 1. 对于DDL, field为crc32(sql)+区域标识, value为serverID 2. 对于插入, field为操作类型标识+主键ID+区域标识， value为来源serverID 3. 对于删除, field为操作类型标识+主键ID+区域标识， value为来源serverID 4. 对于更新, field为操作类型标识+主键ID+crc32(after)+区域标识, value为来源serverID  其中serverID为数据库实例的唯一标识，这里只来源实例。 after为更新后的列数据，在实现中是一个结构体。插入和删除都是幂等的，因此不需要记录列信息，更新操作需要判断是否为同一条语句只用主键是不行的，所以需要记录列信息。  发送端从kafka获取到数据后，先判断数据是否是回环数据，如果是则过滤，然后删除缓存。</description>
    </item>
    
    <item>
      <title>灰度网关</title>
      <link>https://stong1994.github.io/internet/design/gray_gateway/</link>
      <pubDate>Sun, 03 Oct 2021 23:57:00 +0800</pubDate>
      
      <guid>https://stong1994.github.io/internet/design/gray_gateway/</guid>
      <description>背景 对于一个公司来说，在创业初期需要对产品快速迭代来解决用户痛点、提升自己的竞争力进而占领更多的市场（这就是MVP原则的思想）。随着业务的发展，早期的快速迭代导致了代码冗余、混乱、质量低、难以维护等问题，这时候就需要对其进行重构。
但是重构会带来极大的风险，严重的会导致服务崩溃，甚至是数据混乱。这是我们不能接受的。
尽管重构的风险是无法避免的，但是我们却可以通过管控流量将风险降到最低。这就用到了灰度网关。
此外，灰度网关还支持A/B测试等其他方面的功能。
功能简介  支持将旧服务的流量打到新服务 支持按照一定的比例来分配流量 支持按照header或者ip来分配流量 支持动态配置  正常情况下的流量走向 灰度后的流量走向 技术选型 开发网关，那首选就是openresty了。openresty是一个以nginx作为网络通信，以lua语言进行开发的平台，也可以理解为是一套可以通过lua语言对nginx进行扩展的生态。
由于需要支持动态配置，因此需要一个配置中心，我们选择了consul（整体系统的配置中心都是用的consul）。
开发思路 nginx执行阶段选择 先来回顾下nginx的11个执行阶段。
openResty的11个*_by_lua指令，对应了nginx的11个执行阶段。以下是其应用场景：
 init: 只会在 Master 进程被创建时执行 init_worker: 只会在每个 Worker 进程被创建时执行 ssl_certificate: 证书认证 set: 设置变量 rewrite: 转发、重定向 access：权限控制 content：生成内容返回 balancer：负载均衡 header_filter: 响应头过滤 body_filter: 响应体过滤 log: 日志记录  通过上图，我们可以得出结论：我们只能在set、rewrite、access这三个阶段进行灰度处理
判断流量走向 首先，如果url没在配置中，那么流量一定是打入到原环境。
如果url在配置中，那么流量需要按照比例判断是否打入到灰度环境还是原环境。
判断url是否在配置：
 通过ngx.var.uri即可拿到访问url，然后再去配置中心进行匹配即可。  判断该请求打入到哪个环境：
  在头部拿到token：ngx.req.get_headers()
  如果token为空获取ip：
local headers = ngx.req.get_headers() local ip = headers[&amp;#34;X-REAL-IP&amp;#34;] if ip == nil then ip = ngx.</description>
    </item>
    
    <item>
      <title>事件分发平台</title>
      <link>https://stong1994.github.io/internet/design/evps/</link>
      <pubDate>Fri, 01 Oct 2021 19:26:00 +0800</pubDate>
      
      <guid>https://stong1994.github.io/internet/design/evps/</guid>
      <description>背景 随着业务的增长，一个事件开始被多个子系统订阅，如用户注册事件就可能被处理用户逻辑的子系统和日志系统订阅。以往我们在处理这些逻辑的时候，要么在处理完注册逻辑后，调用多个子服务接口，要么用消息队列中间件来处理。这些都导致了较高的维护成本。
另外，整体系统使用了严格的分层，下层服务不能调用上层服务，同层之间也不能调用。如果有回调等需求，也要通过事件的方式来传递数据。
因此，我们基于消息队列的思想，创建了事件分发平台。
架构设计 整个事件分发系统大致由以下构成：
 事件发送方：即事件的生产者 事件订阅方：即事件的消费者 事件分发服务：接收事件，处理事件的发送逻辑 事件管理平台：通过web页面管理事件的配置，显示错误日志等信息  我们主要关注事件分发服务：
 订阅者队列组：每个订阅方（事件接收方）都有自己单独的队列，因此生产者和订阅者队列是一对多的关系。订阅者队列组来管理一个事件的多个订阅队列（实际上订阅队列组在上层还有一个订阅者队列管理器，来统一管理这些订阅队列组，与业务逻辑无关，因此图中未显示）。 订阅者集群组：每个订阅者队列都对应着一个订阅者集群，该集群由多个channel组成，用来加快事件的消费速度。集群具备自动扩容、缩容的功能。 配置中心：配置中心是通过内存来存储着事件的订阅关系。配置中心通过读取或者监听redis的变动，来管理订阅关系。订阅者队列组和订阅者集群组都会读取配置中心并监听配置中心变动，来管理自己的队列或集群。  消息队列中间件的选择 事件分发平台是基于消息队列的思想来构建的，因此需要使用消息队列中间件来管理消息队列。
市面上有许多消息队列中间件，如kafka、rabbitmq等。我们考虑到所需吞吐量并不大，所以初步选择使用redis的列表来实现。使用redis的列表来实现，优势在于能够更快速的完成开发，且整体系统更轻量。
一旦发展到redis的列表不能满足需求时，通过接口或者叫适配器，也能轻松的完成消息队列中间件的切换。
如何监听redis中的事件变动 在事件管理平台将事件订阅关系变动后，会将数据存储到redis中。配置中心如何监听这些数据的变动呢？
每隔一段时间就读取全量数据是最简单的做法，也是最粗暴的做法。因为事件数据有很多，每次读取、对比都需要不少的时间，这就导致事件分发服务对于事件配置的变动很“迟钝”。
我们通过版本号的方法来解决。通过一个hash来存储发送者信息、事件信息、订阅者信息、订阅关系信息的版本号，每次修改这些信息时，都要对其对应的版本号自增。同时，事件分发服务在内存中也会维护这样一个版本号，每隔一段时间（如200ms）读取一次，进行更新，当事件分发服务发现版本号不对的时候，就会去拉取对应的数据，来更新内存中的数据。
这样每次只读取一个很小的hash key即可知道哪些数据需要更新。
消费逻辑 有以下几点需要注意：
 有些订阅者服务需要按照时序来接收事件 系统处于维护状态时，不能接收事件，需要将事件暂存  整体流程图如下：
其中时序功能采用最简单“先到先得”，即按照事件分发服务接收到请求的时间来排序。
可进一步优化的地方 在发送事件时，如果发送失败会进行重试，但是如果超过了重试次数，那么该事件就会丢失。
可考虑在发送失败后报警并每隔一段时间进行发送，直到服务恢复正常，能够正常返回数据时，再继续消费数据。</description>
    </item>
    
    <item>
      <title>统一支付系统</title>
      <link>https://stong1994.github.io/internet/design/basepay/</link>
      <pubDate>Thu, 30 Sep 2021 14:31:11 +0800</pubDate>
      
      <guid>https://stong1994.github.io/internet/design/basepay/</guid>
      <description>背景 已有的支付服务经常出现支付失败、支付状态不准确等问题，且由于历史原因使用的.net开发，维护上有一定困难，因此我们决定重新做一个统一支付系统。
需求 统一支付系统需要满足以下几点需求：
 对接微信、支付宝中的多种支付方式 处理微信、支付宝的回调结果，并通过事件分发平台通知业务方。 开发环境和测试环境要支持1分钱开关，打开开关后，任何支付都是1分钱 支持退款 需要对账功能  架构设计   红色流程为订单的预支付流程。
  黄色流程为用户支付流程，为用户与第三方服务商交互。
  绿色流程为第三方服务商回调流程
  预支付流程  用户在客户端点击商品选择支付 业务系统处理订单逻辑，并调用通用支付系统发起下单请求 通用支付系统调用对应的第三方服务商，获取支付二维码地址或者唤起客户端支付地址，并返回给业务系统，业务系统将其返回给前端 前端接收到地址后，将其转换为二维码或者调换到微信/支付宝客户端支付页面  回调流程   第三方服务商在收到用户支付或者拒绝后，会发送支付结果到回调网关
  回调网关对数据进行解密、校验并将解析出来的数据发往事件分发平台
  由于通用支付系统订阅了该事件，因此事件分发平台会将该事件发送给通用支付系统
  通用支付系统处理支付结果，并将最终的支付状态通过事件分发平台发送给业务子系统
  时序图-以微信的Native支付为例 注意事项 支付和退款分离 由于是统一支付系统，需要兼容各服务商的支付和退款，因此，为了高扩展性，将支付和退款作为两种订单处理，每种都有自己的订单状态
统一支付接口参数 支付宝和微信的支付接口支持非常多的参数，这其中大部分是用不到的，因此在做接口设计时，没必要将这些参数放进去，保持接口的简洁。
统一支付/退款状态 支付宝和微信的支付/退款状态并不同。
 微信有：未支付、已关闭、已撤销、支付失败、支付成功、转入退款、等待扣款 支付宝有：订单创建、交易成功、交易超时或者已全额退款、交易结束  作为统一支付系统，我们需要有自己的一套交易状态来兼容第三方服务商的交易状态。
支付状态：
 交易创建：即未收到任何回调时 交易成功：存在真实的资金流动 交易失败：由于服务商内部服务原因导致交易失败，比如由银行返回的支付失败。 交易关闭：没有真实的资金流动，如交易被撤销，用户付款超时导致交易取消  退款状态：
 退款订单创建 退款关闭 退款成功 退款失败  统一单位 微信支付的最小单位为分，而支付宝的单位为元，支持小数。统一支付接口设计上以分为单位，不支持小数。</description>
    </item>
    
    <item>
      <title>《论个人在历史上的作用问题》</title>
      <link>https://stong1994.github.io/book/philosophy/person_and_history/</link>
      <pubDate>Mon, 15 Mar 2021 00:09:00 +0800</pubDate>
      
      <guid>https://stong1994.github.io/book/philosophy/person_and_history/</guid>
      <description>作者：格奥尔基·普列汉诺夫 豆瓣评分：8.6 出版年: 2010-12 提问 个人与历史之间的关系是怎样的呢？是英雄成就了历史，还是历史成就了英雄？ 解释 不应夸大英</description>
    </item>
    
    <item>
      <title>《债务危机》</title>
      <link>https://stong1994.github.io/book/improve/A_Template_For_Understanding_BIG_DEBT_CRISES/</link>
      <pubDate>Sun, 28 Feb 2021 23:25:51 +0800</pubDate>
      
      <guid>https://stong1994.github.io/book/improve/A_Template_For_Understanding_BIG_DEBT_CRISES/</guid>
      <description>作者：RAY DALID 豆瓣评分：8.7 微信读书评分：8.3 术语 国际收支差额：一个特定国家的个人或机构与世界其他地区之间的所有交易的差额。 国际收支危机</description>
    </item>
    
    <item>
      <title>《原则》</title>
      <link>https://stong1994.github.io/book/improve/principles/</link>
      <pubDate>Sun, 28 Feb 2021 16:19:51 +0800</pubDate>
      
      <guid>https://stong1994.github.io/book/improve/principles/</guid>
      <description>作者：RAY DALIO 微信读书评分: 8.8 豆瓣读书评分：8.3 出版时间：2018-1 《原则》内容摘录 基调 以原则为基础去生活。 核心原则 保持头脑开放（尽管这</description>
    </item>
    
    <item>
      <title>不花一分钱搭建一个博客</title>
      <link>https://stong1994.github.io/life/build_free_blog/</link>
      <pubDate>Sun, 31 Jan 2021 16:30:51 +0800</pubDate>
      
      <guid>https://stong1994.github.io/life/build_free_blog/</guid>
      <description>相关文章 hugo的官方文档 安装hugo 1. 使用安装包 下载地址 2. 源码安装 提前准备好go环境 执行命令：go get -v github.com/gohugoio/hugo 踩坑 有些主题需要使用extende</description>
    </item>
    
    <item>
      <title>《这就是OKR》</title>
      <link>https://stong1994.github.io/book/improve/measure_what_matters/</link>
      <pubDate>Sun, 31 Jan 2021 00:10:51 +0800</pubDate>
      
      <guid>https://stong1994.github.io/book/improve/measure_what_matters/</guid>
      <description>作者：约翰·杜尔（John Doerr） 微信读书评分: 8.4 豆瓣读书评分：7.4 什么是OKR Objectives and Key Results OKR是确保将整个组织的力量都聚焦于完成对所有</description>
    </item>
    
    <item>
      <title>DDD实战-笔记篇</title>
      <link>https://stong1994.github.io/internet/ddd/practise/</link>
      <pubDate>Fri, 29 Jan 2021 23:31:51 +0800</pubDate>
      
      <guid>https://stong1994.github.io/internet/ddd/practise/</guid>
      <description>DDD实战 如何构建中台业务模型？ 1. 自顶向下的策略 这种策略是先做顶层设计，从最高领域逐级分解为中台，分别建立领域模型，根据业务属性分为通用中台或核心中台。领域建模过程主要基于业务现状，暂时不考虑系统现状。自顶向下的策略适用于全新的应用系统建设，或旧系统推倒重建的情况。
2. 自底向上的策略 这种策略是基于业务和系统现状完成领域建模。首先分别完成系统所在业务域的领域建模；然后对齐业务域，找出具有同类或相似业务功能的领域模型，对比分析领域模型的差异，重组领域对象，重构领域模型。这个过程会沉淀公共和复用的业务能力，会将分散的业务模型整合。自底向上策略适用于遗留系统业务模型的演进式重构。
第一步：锁定系统所在业务域，构建领域模型。 锁定系统所在的业务域，采用事件风暴，找出领域对象，构建聚合，划分限界上下文，建立领域模型。
可以看到有很多相似的模块
第二步：对齐业务域，构建中台业务模型 传统核心领域模型明显多于左侧的互联网电商。这个结论也给我们指明了一个方向：首先我们可以将传统核心的领域模型作为主领域模型，将互联网电商领域模型作为辅助模型来构建中台业务模型。然后再将互联网电商中重复的能力沉淀到传统核心的领域模型中，只保留自己的个性能力，比如订单。中台业务建模时，既要关注领域模型的完备性，也要关注不同渠道敏捷响应市场的要求。
我们从互联网电商和传统核心的领域模型中，归纳并分离出能覆盖两个域的所有业务子域。通过分析，我们找到了用户、客户、承保、收付和订单五个业务域，它们是可以用于领域模型对比分析的基准域。
构建多业务域的中台业务模型的过程，就是找出同一业务域内所有同类业务的领域模型，对比分析域内领域模型和聚合的差异和共同点，打破原有的模型，完成新的中台业务模型重组或归并的过程。
重构后
构建中台模型的要点 分域建模型，找准基准域，划定上下文，聚合重归类
第三步：中台归类，根据领域模型设计微服务。 完成中台业务建模后，我们就有了下面这张图。从这张图中我们可以看到总共构建了多少个中台，中台下面有哪些领域模型，哪些中台是通用中台，哪些中台是核心中台，中台的基本信息等等，都一目了然。你根据中台下的领域模型就可以设计微服务了。
重构过程中的领域对象 部分领域对象可能会根据新的业务要求，从原来的聚合中分离，重组到其它聚合。新领域模型的领域对象，比如实体、领域服务等，在重组后可能还会根据新的业务场景和需求进行代码重构。
事件风暴需要准备些什么 1. 事件风暴的参与者 除了领域专家，事件风暴的其他参与者可以是 DDD 专家、架构师、产品经理、项目经理、开发人员和测试人员等项目团队成员。
领域建模是统一团队语言的过程，因此项目团队应尽早地参与到领域建模中，这样才能高效建立起团队的通用语言。
2. 事件风暴要准备的材料 事件风暴参与者会将自己的想法和意见写在即时贴上，并将贴纸贴在墙上的合适位置，我们戏称这个过程是“刷墙”。所以即时贴和水笔是必备材料，另外，你还可以准备一些胶带或者磁扣，以便贴纸随时能更换位置。
值得提醒一下的是，在这个过程中，我们要用不同颜色的贴纸区分领域行为。如下图，我们可以用蓝色表示命令，用绿色表示实体，橙色表示领域事件，黄色表示补充信息等。补充信息主要用来说明注意事项，比如外部依赖等。颜色并不固定，这只是我的习惯，团队内统一才是重点。
3. 事件风暴的场地 只需要一堵足够长的墙和足够大的空间就可以了。墙是用来贴纸的，大空间可以让人四处走动，方便合作。撤掉会议桌和椅子的事件风暴，你会发现参与者们的效率更高。
4. 事件风暴分析的关注点 在领域建模的过程中，我们需要重点关注这类业务的语言和行为。比如某些业务动作或行为（事件）是否会触发下一个业务动作，这个动作（事件）的输入和输出是什么？是谁（实体）发出的什么动作（命令），触发了这个动作（事件）…我们可以从这些暗藏的词汇中，分析出领域模型中的事件、命令和实体等领域对象。
如何用事件风暴构建领域模型 1. 产品愿景 产品愿景的主要目的是对产品顶层价值的设计，使产品目标用户、核心价值、差异化竞争点等信息达成一致，避免产品偏离方向。
在建模之前，项目团队要思考这样两点：
 用户中台到底能够做什么？ 它的业务范围、目标用户、核心价值和愿景，与其它同类产品的差异和优势在哪里？  2. 业务场景分析 场景分析是从用户视角出发的，根据业务流程或用户旅程，采用用例和场景分析，探索领域中的典型场景，找出领域事件、实体和命令等领域对象，支撑领域建模。事件风暴参与者要尽可能地遍历所有业务细节，充分发表意见，不要遗漏业务要点。
场景分析时会产生很多的命令和领域事件。我用蓝色来表示命令，用橙色表示领域事件，用黄色表示补充信息，比如用户信息数据来源于 HR 系统的说明。
3. 领域建模 领域建模时，我们会根据场景分析过程中产生的领域对象，比如命令、事件等之间关系，找出产生命令的实体，分析实体之间的依赖关系组成聚合，为聚合划定限界上下文，建立领域模型以及模型之间的依赖。领域模型利用限界上下文向上可以指导微服务设计，通过聚合向下可以指导聚合根、实体和值对象的设计
第一步：从命令和事件中提取产生这些行为的实体。用绿色贴纸表示实体。通过分析用户中台的命令和事件等行为数据，提取了产生这些行为的用户、账户、认证票据、系统、菜单、岗位和用户日志七个实体。
第二步：根据聚合根的管理性质从七个实体中找出聚合根，比如，用户管理用户相关实体以及值对象，系统可以管理与系统相关的菜单等实体等，可以找出用户和系统等聚合根。然后根据业务依赖和业务内聚原则，将聚合根以及它关联的实体和值对象组合为聚合，比如系统和菜单实体可以组合为“系统功能”聚合。按照上述方法，用户中台就有了系统功能、岗位、用户信息、用户日志、账户和认证票据六个聚合。
第三步：划定限界上下文，根据上下文语义将聚合归类。根据用户域的上下文语境，用户基本信息和用户日志信息这两个聚合共同构成用户信息域，分别管理用户基本信息、用户登录和操作日志。认证票据和账户这两个聚合共同构成认证域，分别实现不同方式的登录和认证。系统功能和岗位这两个聚合共同构成权限域，分别实现系统和菜单管理以及系统的岗位配置。根据业务边界，我们可以将用户中台划分为三个限界上下文：用户信息、认证和权限。
4. 微服务拆分与设计 原则上一个领域模型就可以设计为一个微服务，但由于领域建模时只考虑了业务因素，没有考虑微服务落地时的技术、团队以及运行环境等非业务因素，因此在微服务拆分与设计时，我们不能简单地将领域模型作为拆分微服务的唯一标准，它只能作为微服务拆分的一个重要依据。
微服务的设计还需要考虑服务的粒度、分层、边界划分、依赖关系和集成关系。除了考虑业务职责单一外，我们还需要考虑将敏态与稳态业务的分离、非功能性需求（如弹性伸缩要求、安全性等要求）、团队组织和沟通效率、软件包大小以及技术异构等非业务因素。
代码模型 没有一个统一的代码模型。
微服务目录架构 按照 DDD 分层架构的分层职责来定义，分别为用户接口层、应用层、领域层和基础层。</description>
    </item>
    
    <item>
      <title>DDD进阶-笔记篇</title>
      <link>https://stong1994.github.io/internet/ddd/advance/</link>
      <pubDate>Fri, 29 Jan 2021 23:31:51 +0800</pubDate>
      
      <guid>https://stong1994.github.io/internet/ddd/advance/</guid>
      <description>领域事件 如何识别领域事件 很简单，和刚才讲的定义是强关联的。在做用户旅程或者场景分析时，我们要捕捉业务、需求人员或领域专家口中的关键词：“如果</description>
    </item>
    
    <item>
      <title>《卓有成效的管理者》</title>
      <link>https://stong1994.github.io/book/improve/the_effective_executive/</link>
      <pubDate>Fri, 29 Jan 2021 23:31:51 +0800</pubDate>
      
      <guid>https://stong1994.github.io/book/improve/the_effective_executive/</guid>
      <description>作者：彼得·德鲁克 豆瓣评分：8.7 微信评分：8.9 出版年: 2005-6 提纲 1. 谁是管理者 如果一个工作者能够凭借其职位和知识，对其组织负有贡献的责任并能够</description>
    </item>
    
    <item>
      <title>DDD基础-笔记篇</title>
      <link>https://stong1994.github.io/internet/ddd/base/</link>
      <pubDate>Fri, 29 Jan 2021 23:07:51 +0800</pubDate>
      
      <guid>https://stong1994.github.io/internet/ddd/base/</guid>
      <description>中台面临的问题：作为中台，需要将通用的可复用的业务能力沉淀到中台业务模型，实现企业级能力复用。因此中台面临的首要问题就是中台领域模型的重构。而中台落地时，依然会面临微服务设计和拆分的问题。
基础 组织架构演进
DDD解决的问题 DDD 核心思想是通过领域驱动设计方法定义领域模型，从而确定业务和应用边界，保证业务模型与代码模型的一致性。
DDD 强调领域模型和微服务设计的一体性，先有领域模型然后才有微服务，而不是脱离领域模型来谈微服务设计。
其次，就是通过战略设计，建立领域模型，划分微服务边界。
最后，通过战术设计，我们会从领域模型转向微服务设计和落地。
战略设计 战略设计主要从业务视角出发，建立业务领域模型，划分领域边界，建立通用语言的限界上下文，限界上下文可以作为微服务设计的参考边界。
三步来划定领域模型和微服务的边界  在事件风暴中梳理业务过程中的用户操作、事件以及外部依赖关系等，根据这些要素梳理出领域实体等领域对象。 根据领域实体之间的业务关联性，将业务紧密相关的实体进行组合形成聚合，同时确定聚合中的聚合根、值对象和实体。在这个图里，聚合之间的边界是第一层边界，它们在同一个微服务实例中运行，这个边界是逻辑边界，所以用虚线表示。 根据业务及语义边界等因素，将一个或者多个聚合划定在一个限界上下文内，形成领域模型。在这个图里，限界上下文之间的边界是第二层边界，这一层边界可能就是未来微服务的边界，不同限界上下文内的领域逻辑被隔离在不同的微服务实例中运行，物理上相互隔离，所以是物理边界，边界之间用实线来表示。  战术设计 战术设计则从技术视角出发，侧重于领域模型的技术实现，完成软件开发和落地，包括：聚合根、实体、值对象、领域服务、应用服务和资源库等代码逻辑的设计和实现。
基本概念   头脑风暴: DDD 领域建模通常采用事件风暴，它通常采用用例分析、场景分析和用户旅程分析等方法，通过头脑风暴列出所有可能的业务行为和事件，然后找出产生这些行为的领域对象，并梳理领域对象之间的关系，找出聚合根，找出与聚合根业务紧密关联的实体和值对象，再将聚合根、实体和值对象组合，构建聚合。
  领域：在研究和解决业务问题时，DDD 会按照一定的规则将业务领域进行细分，当领域细分到一定的程度后，DDD 会将问题范围限定在特定的边界内，在这个边界内建立领域模型，进而用代码实现该领域模型，解决相应的业务问题。简言之，DDD 的领域就是这个边界内要解决的业务问题域。
  子领域：我们把划分出来的多个子领域称为子域，每个子域对应一个更小的问题域或更小的业务范围。
  核心域：决定产品和公司核心竞争力的子域是核心域，它是业务成功的主要因素和公司的核心竞争力。
  通用域：没有太多个性化的诉求，同时被多个子域使用的通用功能子域是通用域。
  支撑域：既不包含决定产品和公司核心竞争力的功能，也不包含通用功能的功能子域。
  通用语言：在事件风暴过程中，通过团队交流达成共识的，能够简单、清晰、准确描述业务涵义和规则的语言就是通用语言。
 通用语言包含术语和用例场景，并且能够直接反映在代码中。通用语言中的名词可以给领域对象命名，如商品、订单等，对应实体对象；而动词则表示一个动作或事件，如商品已下单、订单已付款等，对应领域事件或者命令。
   上下文边界：用来确定语义所在的领域边界。一个上下文边界理论上就可以设计为一个微服务。
  实体：在 DDD 中有这样一类对象，它们拥有唯一标识符，且标识符在历经各种状态变更后仍能保持一致。对这些对象而言，重要的不是其属性，而是其延续性和标识，对象的延续性和标识会跨越甚至超出软件的生命周期。我们把这样的对象称为实体。
  值对象：通过对象属性值来识别的对象，它将多个相关属性组合为一个概念整体。在 DDD 中用来描述领域的特定方面，并且是一个没有标识符的对象，叫作值对象。在领域建模的过程中，值对象可以保证属性归类的清晰和概念的完整性，避免属性零碎。将“省、市、县和街道等属性”拿出来构成一个“地址属性集合”，这个集合就是值对象了
  聚合：聚合就是由业务和逻辑紧密关联的实体和值对象组合而成的，聚合是数据修改和持久化的基本单元，每一个聚合对应一个仓储，实现数据的持久化。
  聚合根：聚合根的主要目的是为了避免由于复杂数据模型缺少统一的业务规则控制，而导致聚合、实体之间数据不一致性的问题。
 如果把聚合比作组织，那聚合根就是这个组织的负责人。聚合根也称为根实体，它不仅是实体，还是聚合的管理者。</description>
    </item>
    
  </channel>
</rss>
